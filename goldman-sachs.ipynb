{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.preprocessing import LabelBinarizer\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-03T11:37:10.229687Z","iopub.execute_input":"2021-10-03T11:37:10.229958Z","iopub.status.idle":"2021-10-03T11:37:15.895043Z","shell.execute_reply.started":"2021-10-03T11:37:10.229931Z","shell.execute_reply":"2021-10-03T11:37:15.894302Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Webscraper","metadata":{}},{"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport requests\n\n\ndef get_tickers():\n    wiki_page = requests.get(\n        'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies').text\n    sp_data = pd.read_html(wiki_page)\n    ticker_df = sp_data[0]\n    ticker_options = ticker_df['Symbol']\n    return ticker_options\n\n\ndef level(x):\n    if x == 0:\n        return 'No Controversy'\n    elif x == 1.0:\n        return 'Little Controversy'\n    elif x == 2.0:\n        return 'Moderate Controversy'\n    elif x == 3.0:\n        return 'Relatively High Controversy'\n    else:\n        return 'High Controversy'\n\n\ndef web_scraper(ticker):\n    elements = []\n    url = 'https://finance.yahoo.com/quote/'+ticker+'/sustainability?p='+ticker\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'}\n    web_data = requests.get(url, headers=headers, timeout=5).text\n\n    soup = BeautifulSoup(web_data, 'html.parser')\n    esg_score = soup.find(\"div\", {'class': 'Fz(36px) Fw(600) D(ib) Mend(5px)'})\n    if(esg_score == None):\n        return pd.DataFrame()\n    datapoint = 100 - int(esg_score.text)\n    controversy_score = soup.find('div', {'class': 'D(ib) Fz(36px) Fw(500)'})\n    if(controversy_score == None):\n        return pd.DataFrame()\n    controversy_datapoint = controversy_score.text\n    if(controversy_datapoint == None):\n        return pd.DataFrame()\n    scores = soup.find_all(\n        'div', {'class': 'D(ib) Fz(23px) smartphone_Fz(22px) Fw(600)'})\n\n    for score in scores:\n        elements.append(round(33.3 - float(score.text),2))\n\n    df = pd.DataFrame({'Total ESG Score': datapoint,\n                       'Environment Score': elements[0],\n                       'Social Score': elements[1],\n                       'Governance Score': elements[2],\n                       'Controversy Score': int(controversy_datapoint)},\n                      index=[ticker])\n    return df\n\n\ndef get_esg(ticker):\n    esg_data = web_scraper(ticker)\n    return esg_data","metadata":{"execution":{"iopub.status.busy":"2021-10-03T02:38:07.930615Z","iopub.execute_input":"2021-10-03T02:38:07.930929Z","iopub.status.idle":"2021-10-03T02:38:07.95196Z","shell.execute_reply.started":"2021-10-03T02:38:07.930897Z","shell.execute_reply":"2021-10-03T02:38:07.950996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"code","source":"dirname = '/kaggle/input/aws-esg/ADX_ESG_NEWS_2020-09-01.csv'\n\ndf = pd.read_csv(dirname)\ndf= df[df['totalCountDailyScore'] != 0]","metadata":{"execution":{"iopub.status.busy":"2021-10-03T04:49:38.702686Z","iopub.execute_input":"2021-10-03T04:49:38.70405Z","iopub.status.idle":"2021-10-03T04:49:42.29827Z","shell.execute_reply.started":"2021-10-03T04:49:38.703995Z","shell.execute_reply":"2021-10-03T04:49:42.297418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique = df.drop_duplicates(subset=['ticker'])\nunique = unique.loc[:, ['ticker', 'companyName']]\n\nticker = list(unique['ticker'])\ncompanyName = list(unique['companyName'])\n\nresult = zip(ticker, companyName)\n\nresult = list(result)\n\ncompanies_dict = {}\n\nn = 1\nfor x in result:\n    \n    score = get_esg(x[0]).values.tolist()\n    print(n)\n    if len(score) == 0:\n        continue\n    n += 1\n    score = score[0]\n    companies_dict[x[0]] = [x[1], score]\n    \n\n\nwith open('companies.json', 'w', encoding='utf-8') as f:\n    json.dump(companies_dict, f, ensure_ascii=False, indent=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"daily_score = list(df_new['totalCountDailyScore'])\ndate = list(df_new['date'])\n\nresult = zip(date, daily_score)\n\nresult = list(result)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T01:25:58.067293Z","iopub.execute_input":"2021-10-03T01:25:58.068086Z","iopub.status.idle":"2021-10-03T01:25:58.073162Z","shell.execute_reply.started":"2021-10-03T01:25:58.068052Z","shell.execute_reply":"2021-10-03T01:25:58.072303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/companies/companies.json', 'r') as f:\n    data=f.read()\n\ndata = json.loads(data)\n\ndata = list(data.keys())\nprint(len(data))\n\nboolean_series = df.ticker.isin(data)\nfiltered_df = df[boolean_series]","metadata":{"execution":{"iopub.status.busy":"2021-10-03T05:26:06.649012Z","iopub.execute_input":"2021-10-03T05:26:06.650159Z","iopub.status.idle":"2021-10-03T05:26:06.688817Z","shell.execute_reply.started":"2021-10-03T05:26:06.650102Z","shell.execute_reply":"2021-10-03T05:26:06.687396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x={}\nn=0\nprint(len(data))\nfor name in data:\n    df_new = df.loc[df['ticker'] == name, ['ticker', 'companyName', 'date', 'totalCountDailyScore']]\n    df_new['totalCountDailyScore'] = ((1 - ((df_new.loc[:, 'totalCountDailyScore'] + 1) / 3.5)) * 100).astype(int)\n    date = df_new['date'].values.tolist()\n    score = df_new['totalCountDailyScore'].values.tolist()\n    combined = list(zip(date, score))\n    \n    x[df_new['ticker'].values[0]] = { \n    \"companyName\": df_new['companyName'].values[0],\n    \"values\": combined\n    }\n    \nprint('done')\n\nwith open('time.json', 'w', encoding='utf-8') as f:\n    json.dump(x, f, ensure_ascii=False, indent=4)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T05:21:56.421655Z","iopub.execute_input":"2021-10-03T05:21:56.421958Z","iopub.status.idle":"2021-10-03T05:22:05.533973Z","shell.execute_reply.started":"2021-10-03T05:21:56.421926Z","shell.execute_reply":"2021-10-03T05:22:05.533079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/companies/time.json', 'r') as f:\n    data=f.read()\n\ndata = json.loads(data)\n\nnames = list(data.keys())\n\nx = {}\nfor name in names:\n    esg = []\n    for score in data[name]['values']:\n        esg.append(score[1])\n    \n    x[name] = esg","metadata":{"execution":{"iopub.status.busy":"2021-10-03T11:01:03.522551Z","iopub.execute_input":"2021-10-03T11:01:03.522838Z","iopub.status.idle":"2021-10-03T11:01:03.6172Z","shell.execute_reply.started":"2021-10-03T11:01:03.5228Z","shell.execute_reply":"2021-10-03T11:01:03.615801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler(feature_range = (0, 1))\n\nwith open('/kaggle/input/companies/time.json', 'r') as f:\n    data=f.read()\n\ndata = json.loads(data)\nesg = []\n\nfor score in data['GOOGL']['values']:\n    esg.append(score[1])\nesg = np.array(esg).reshape(-1, 1)\nesg_scaled= scaler.fit_transform(esg)\n\nesg_scaled\n\nfeatures_set = []\nlabels = []\nfor i in range(60, len(esg_scaled)):\n    features_set.append(esg_scaled[i-60:i, 0])\n    labels.append(esg_scaled[i, 0])\n    \nfeatures_set, labels = np.array(features_set), np.array(labels)\nfeatures_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))","metadata":{"execution":{"iopub.status.busy":"2021-10-03T11:37:32.929322Z","iopub.execute_input":"2021-10-03T11:37:32.929644Z","iopub.status.idle":"2021-10-03T11:37:33.257063Z","shell.execute_reply.started":"2021-10-03T11:37:32.929616Z","shell.execute_reply":"2021-10-03T11:37:33.256091Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Creating Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout\n\nmodel = Sequential()\nmodel.add(LSTM(units=50, return_sequences=True, input_shape=(features_set.shape[1], 1)))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=50, return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=50, return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(units=50))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units = 1))\nmodel.compile(optimizer = 'adam', loss = 'mean_squared_error')","metadata":{"execution":{"iopub.status.busy":"2021-10-03T11:37:37.460076Z","iopub.execute_input":"2021-10-03T11:37:37.460385Z","iopub.status.idle":"2021-10-03T11:37:38.613453Z","shell.execute_reply.started":"2021-10-03T11:37:37.460352Z","shell.execute_reply":"2021-10-03T11:37:38.612630Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model.fit(features_set, labels, epochs = 30, batch_size = 32)","metadata":{"execution":{"iopub.status.busy":"2021-10-03T11:37:42.026835Z","iopub.execute_input":"2021-10-03T11:37:42.027494Z","iopub.status.idle":"2021-10-03T11:39:09.405824Z","shell.execute_reply.started":"2021-10-03T11:37:42.027439Z","shell.execute_reply":"2021-10-03T11:39:09.405225Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"test_inputs = esg_scaled[len(esg_scaled) - 60:]\n\ntest_inputs = test_inputs.reshape(-1,1)\n\ntest_features = []\nfor i in range(60, 61):\n    test_features.append(test_inputs[i-64:i, 0])","metadata":{"execution":{"iopub.status.busy":"2021-10-03T11:41:06.459062Z","iopub.execute_input":"2021-10-03T11:41:06.459393Z","iopub.status.idle":"2021-10-03T11:41:06.466275Z","shell.execute_reply.started":"2021-10-03T11:41:06.459363Z","shell.execute_reply":"2021-10-03T11:41:06.464951Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"test_features = np.array(test_features)\ntest_features = np.reshape(test_features, (test_features.shape[0], test_features.shape[1], 1))","metadata":{"execution":{"iopub.status.busy":"2021-10-03T11:41:09.149527Z","iopub.execute_input":"2021-10-03T11:41:09.150272Z","iopub.status.idle":"2021-10-03T11:41:09.153986Z","shell.execute_reply.started":"2021-10-03T11:41:09.150227Z","shell.execute_reply":"2021-10-03T11:41:09.153327Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_features)\npredictions = scaler.inverse_transform(predictions)\npredictions","metadata":{"execution":{"iopub.status.busy":"2021-10-03T11:41:12.569341Z","iopub.execute_input":"2021-10-03T11:41:12.569616Z","iopub.status.idle":"2021-10-03T11:41:14.067709Z","shell.execute_reply.started":"2021-10-03T11:41:12.569587Z","shell.execute_reply":"2021-10-03T11:41:14.067074Z"},"trusted":true},"execution_count":8,"outputs":[]}]}